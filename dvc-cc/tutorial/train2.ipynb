{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "_StoreAction(option_strings=['--dataset'], dest='dataset', nargs=None, const=None, default='fashion_mnist', type=<class 'str'>, choices=None, help=None, metavar=None)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int,default=None)\n",
    "parser.add_argument('--num_of_hidden_layers', type=int,default=1)\n",
    "parser.add_argument('--num_of_kernels', type=int,default=64)\n",
    "parser.add_argument('--dropout_rate', type=float,default=0.2)\n",
    "parser.add_argument('--learning_rate', type=float,default=0.001)\n",
    "parser.add_argument('--activation_function', type=str,default='relu')\n",
    "parser.add_argument('--batch_size', type=int,default=1000)\n",
    "parser.add_argument('--epochs', type=int,default=2)\n",
    "parser.add_argument('--dataset', type=str,default='fashion_mnist')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'dcs - DVC-CC-Show this cell in the py file.\\nargs = parser.parse_args()\\n'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "\"\"\"dcs - DVC-CC-Show this cell in the py file.\n",
    "args = parser.parse_args()\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#dch - Hide this cell in the py file!\n",
    "args = parser.parse_args('--num_of_hidden_layers 1 --num_of_kernels 8 --batch_size 100 '\n",
    "                         '--epochs 2'.split())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "if not args.seed is None:\n",
    "    np.random.seed(args.seed)\n",
    "import tensorflow as tf\n",
    "if not args.seed is None:\n",
    "    tf.random.set_seed(args.seed+100)\n",
    "import yaml\n",
    "import time\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LOAD DATASET\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "if args.dataset not in ['fashion_mnist','mnist','cifar10','cifar100']:\n",
    "    raise ValueError('Did not find a dataset with this Name.')\n",
    "\n",
    "num_of_tries = 0\n",
    "while num_of_tries < 100:\n",
    "    try:\n",
    "        if args.dataset == 'fashion_mnist':\n",
    "            (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "            num_of_tries = 99999999\n",
    "        elif args.dataset == 'mnist':\n",
    "            (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "            num_of_tries = 99999999\n",
    "        elif args.dataset == 'cifar10':\n",
    "            (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "            num_of_tries = 99999999\n",
    "        elif args.dataset == 'cifar100':\n",
    "            (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "            num_of_tries = 99999999\n",
    "        else:\n",
    "            raise ValueError('Did not find a dataset with this Name.')\n",
    "    except:\n",
    "        if num_of_tries < 12:\n",
    "            num_of_tries += 1\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            raise ValueError('The data could not be downloaded.')\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dch - Hide this cell in the py file!\n",
    "x_train, x_test = x_train[:1000], x_test[:200] \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BUILD MODEL\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 784)               0         \n_________________________________________________________________\ndense (Dense)                (None, 8)                 6280      \n_________________________________________________________________\ndropout (Dropout)            (None, 8)                 0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                90        \n=================================================================\nTotal params: 6,370\nTrainable params: 6,370\nNon-trainable params: 0\n_________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=x_train.shape[1:]))\n",
    "for i in range(args.num_of_hidden_layers):\n",
    "    model.add(tf.keras.layers.Dense(args.num_of_kernels, activation=args.activation_function))\n",
    "    model.add(tf.keras.layers.Dropout(args.dropout_rate))\n",
    "model.add(tf.keras.layers.Dense(y_train.max()+1, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=args.learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "callbacks = [\n",
    "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
    "  tf.keras.callbacks.EarlyStopping(patience=100, monitor='val_loss'),\n",
    "  # Write TensorBoard logs to `./tensorboard` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='tensorboard'),\n",
    "  tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='model.h5',\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            verbose=2)\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### TRAIN MODEL\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\nW0920 12:29:21.280424 139785856010048 deprecation.py:323] From /home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\nEpoch 1/2\n",
      "\nEpoch 00001: val_loss improved from inf to 0.71210, saving model to model.h5\n54000/54000 - 3s - loss: 1.3308 - acc: 0.5234 - val_loss: 0.7121 - val_acc: 0.7842\n",
      "Epoch 2/2\n",
      "\nEpoch 00002: val_loss improved from 0.71210 to 0.59349, saving model to model.h5\n54000/54000 - 2s - loss: 0.8708 - acc: 0.6860 - val_loss: 0.5935 - val_acc: 0.8110\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f21ef66c710>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=args.epochs, batch_size=args.batch_size, validation_split=0.1,\n",
    "          callbacks=callbacks, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TEST MODEL\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SAVE SUMMARY"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "summary = {'loss': float(np.min(model.history.history['loss'])),\n",
    "            'val_loss': float(np.min(model.history.history['val_loss'])),\n",
    "            'acc': float(np.max(model.history.history['acc'])),\n",
    "            'val_acc': float(np.max(model.history.history['val_acc']))\n",
    "          }\n",
    "with open('summary.yml', 'w') as f:\n",
    "    yaml.dump(summary, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
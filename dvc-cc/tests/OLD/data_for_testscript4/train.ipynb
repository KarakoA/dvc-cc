{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# this script can train a network on the pcam dataset.\n",
    "Imports\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import HDF5Matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import argparse\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "/home/j/test_pcam/repo\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import os\n",
    "if os.getcwd().endswith('code'):\n",
    "    os.chdir('..')\n",
    "print(os.getcwd())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% dch\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "build arparser\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# define the training\n",
    "parser.add_argument('-lr', '--learning-rate', type=float, help='', default = 0.1)\n",
    "parser.add_argument('-b','--batch-size', type=int, help='', default = 64)\n",
    "parser.add_argument('--num-of-epochs', type=int, help='', default = 2)\n",
    "\n",
    "# define the model structure\n",
    "parser.add_argument('--activation-function', type=str, help='', default = 'relu')\n",
    "parser.add_argument('--use-same-padding', action='store_true')\n",
    "parser.add_argument('--kernel-width', type=int, help='', default = 3)\n",
    "parser.add_argument('--average-kernels', type=int, help='', default = 32)\n",
    "parser.add_argument('--num-of-conv-layers', type=int, help='', default = 5)\n",
    "parser.add_argument('--kernel-increasing-factor', type=float, help='', default = 1.2)\n",
    "parser.add_argument('--maxpool-after-n-layer', type=int, help='', default = 3)\n",
    "parser.add_argument('--dropout-factor-after-conv', type=float, help='', default = 0.1)\n",
    "parser.add_argument('--dropout-factor-after-maxp', type=float, help='', default = 0.25)\n",
    "\n",
    "# define the input\n",
    "parser.add_argument('--flip-input', action='store_true')\n",
    "parser.add_argument('--normalize-input', action='store_true')\n",
    "parser.add_argument('--use-cropping', action='store_true')\n",
    "\n",
    "validation_steps=20\n",
    "steps_per_epoch=100\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-lr LEARNING_RATE] [-b BATCH_SIZE]\n                             [--num-of-epochs NUM_OF_EPOCHS]\n                             [--activation-function ACTIVATION_FUNCTION]\n                             [--use-same-padding]\n                             [--kernel-width KERNEL_WIDTH]\n                             [--average-kernels AVERAGE_KERNELS]\n                             [--num-of-conv-layers NUM_OF_CONV_LAYERS]\n                             [--kernel-increasing-factor KERNEL_INCREASING_FACTOR]\n                             [--maxpool-after-n-layer MAXPOOL_AFTER_N_LAYER]\n                             [--dropout-factor-after-conv DROPOUT_FACTOR_AFTER_CONV]\n                             [--dropout-factor-after-maxp DROPOUT_FACTOR_AFTER_MAXP]\n                             [--flip-input] [--normalize-input]\n                             [--use-cropping]\nipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-ae47c4cf-e5f5-4d9c-937a-0e7bfb2c4912.json\n",
      "/home/j/anaconda3/envs/dvc-cc/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ],
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error"
    }
   ],
   "source": [
    "args = parser.parse_args()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        print()\n",
    "        \n",
    "args = Args()\n",
    "\n",
    "args.learning_rate = 0.1\n",
    "args.batch_size = 64\n",
    "args.num_of_epochs = 3\n",
    "\n",
    "args.activation_function = 'relu' ##########\n",
    "args.use_same_padding = True ##############\n",
    "args.kernel_width = 3 ######################\n",
    "args.average_kernels = 64 ###########\n",
    "args.kernel_increasing_factor = 1.5 ###########\n",
    "args.num_of_conv_layers = 5 #############################\n",
    "args.dropout_factor_after_conv = 0.1 ##########\n",
    "args.dropout_factor_after_maxp = 0.25 #########\n",
    "\n",
    "args.maxpool_after_n_layer = 2\n",
    "\n",
    "args.flip_input = True\n",
    "args.normalize_input = True\n",
    "args.use_cropping = True\n",
    "\n",
    "validation_steps=2\n",
    "steps_per_epoch=10\n",
    "\n",
    "#  dvc-cc dummy new -d data/camelyonpatch_level_2_split_train_x.h5 -d data/camelyonpatch_level_2_split_train_y.h5 -d data/camelyonpatch_level_2_split_valid_x.h5 -d data/camelyonpatch_level_2_split_valid_y.h5 -o tf_models/lr<<<learning_rate>>>_bz<<<batch_size>>>_<<<activation_function>>>_same<<<use_same_padding>>>_kw<<<kernel_width>>>_ak<<<average_kernels>>>_if<<<kernel_increasing_factor>>>_n<<<num_of_conv_layers>>>_dfc<<<dropout_factor_after_conv>>>_dfm<<<dropout_factor_after_maxp>>>_m<<<maxpool_after_n_layer>>>_fl<<<flip_input>>>_no<<<normalize_input>>>_cr<<<use_cropping>>>.h5 -o tensorboards/lr<<<learning_rate>>>_bz<<<batch_size>>>_<<<activation_function>>>_same<<<use_same_padding>>>_kw<<<kernel_width>>>_ak<<<average_kernels>>>_if<<<kernel_increasing_factor>>>_n<<<num_of_conv_layers>>>_dfc<<<dropout_factor_after_conv>>>_dfm<<<dropout_factor_after_maxp>>>_m<<<maxpool_after_n_layer>>>_fl<<<flip_input>>>_no<<<normalize_input>>>_cr<<<use_cropping>>> -f dvc/train.dvc --no-exec python code/train.py --lr <<<learning_rate>>> --b <<<batch_size>>> --activation-function <<<activation_function>>> --use-same-padding <<<use_same_padding>>> --kernel-width <<<kernel_width>>> --average-kernels <<<average_kernels>>> --kernel-increasing-factor <<<kernel_increasing_factor>>> --num-of-conv-layers <<<num_of_conv_layers>>> --dropout-factor-after-conv <<<dropout_factor_after_conv>>> --dropout-factor-after-maxp <<<dropout_factor_after_maxp>>> --maxpool-after-n-layer <<<maxpool_after_n_layer>>> --flip-input <<<flip_input>>> --normalize-input <<<normalize_input>>> --use-cropping <<<use_cropping>>>\n",
    "\n",
    "#  lr<<<learning_rate>>>_bz<<<batch_size>>>_<<<activation_function>>>_same<<<use_same_padding>>>_kw<<<kernel_width>>>_ak<<<average_kernels>>>_if<<<kernel_increasing_factor>>>_n<<<num_of_conv_layers>>>_dfc<<<dropout_factor_after_conv>>>_dfm<<<dropout_factor_after_maxp>>>_m<<<maxpool_after_n_layer>>>_fl<<<flip_input>>>_no<<<normalize_input>>>_cr<<<use_cropping>>>\n",
    "#  --lr <<<learning_rate>>> --b <<<batch_size>>> --activation-function <<<activation_function>>> --use-same-padding <<<use_same_padding>>> --kernel-width <<<kernel_width>>> --average-kernels <<<average_kernels>>> --kernel-increasing-factor <<<kernel_increasing_factor>>> --num-of-conv-layers <<<num_of_conv_layers>>> --dropout-factor-after-conv <<<dropout_factor_after_conv>>> --dropout-factor-after-maxp <<<dropout_factor_after_maxp>>> --maxpool-after-n-layer <<<maxpool_after_n_layer>>> --flip-input <<<flip_input>>> --normalize-input <<<normalize_input>>> --use-cropping <<<use_cropping>>>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% dvc-cc-hide\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the dataset:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "x_train = HDF5Matrix('data/camelyonpatch_level_2_split_train_x.h5', 'x')\n",
    "y_train = HDF5Matrix('data/camelyonpatch_level_2_split_train_y.h5', 'y')\n",
    "x_valid = HDF5Matrix('data/camelyonpatch_level_2_split_valid_x.h5', 'x')\n",
    "y_valid = HDF5Matrix('data/camelyonpatch_level_2_split_valid_y.h5', 'y')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "define the model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "if args.use_same_padding:\n",
    "    padding = 'same'\n",
    "else:\n",
    "    padding = 'valid'\n",
    "\n",
    "kernel2d = (args.kernel_width, args.kernel_width)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = Sequential()\n",
    "for i in range(args.num_of_conv_layers):\n",
    "    kernels = args.average_kernels * (args.kernel_increasing_factor ** (i-(args.num_of_conv_layers/2.)))\n",
    "    kernels = int(kernels+0.5)\n",
    "    \n",
    "    if i == 0:\n",
    "        input_shape = list(x_train.shape[1:])\n",
    "        if args.use_cropping:\n",
    "            input_shape[0] -= 10\n",
    "            input_shape[1] -= 10 \n",
    "        \n",
    "        model.add(Conv2D(kernels, kernel2d, padding=padding,\n",
    "                 input_shape=input_shape))\n",
    "    else:\n",
    "        model.add(Conv2D(kernels, kernel2d, padding=padding))\n",
    "    model.add(Activation(args.activation_function))\n",
    "    if args.maxpool_after_n_layer > 0 and (i+1) % args.maxpool_after_n_layer == 0:\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        if args.dropout_factor_after_maxp > 0:\n",
    "            model.add(Dropout(args.dropout_factor_after_maxp))\n",
    "    elif args.dropout_factor_after_conv > 0:\n",
    "        model.add(Dropout(args.dropout_factor_after_conv))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "if args.dropout_factor_after_maxp > 0:\n",
    "    model.add(Dropout(args.dropout_factor_after_maxp))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_5 (Conv2D)            (None, 86, 86, 23)        644       \n_________________________________________________________________\nactivation_6 (Activation)    (None, 86, 86, 23)        0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 86, 86, 23)        0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 86, 86, 35)        7280      \n_________________________________________________________________\nactivation_7 (Activation)    (None, 86, 86, 35)        0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 43, 43, 35)        0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 43, 43, 35)        0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 43, 43, 52)        16432     \n_________________________________________________________________\nactivation_8 (Activation)    (None, 43, 43, 52)        0         \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 43, 43, 52)        0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 43, 43, 78)        36582     \n_________________________________________________________________\nactivation_9 (Activation)    (None, 43, 43, 78)        0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 21, 21, 78)        0         \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 21, 21, 78)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 21, 21, 118)       82954     \n_________________________________________________________________\nactivation_10 (Activation)   (None, 21, 21, 118)       0         \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 21, 21, 118)       0         \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 118)               0         \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 118)               0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 118)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 238       \n_________________________________________________________________\nactivation_11 (Activation)   (None, 2)                 0         \n=================================================================\nTotal params: 144,130\nTrainable params: 144,130\nNon-trainable params: 0\n_________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(args.learning_rate)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy',tf.keras.metrics.AUC()])\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "data loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def next_data_pcam(x,y,bz=args.batch_size):\n",
    "    datalen = len(x)\n",
    "    while True:\n",
    "        indizies = None\n",
    "        while indizies is None or len(indizies) == bz:\n",
    "            indizies = np.unique(sorted(np.random.randint(datalen,size=bz)))\n",
    "        \n",
    "        x_data = np.array(x[indizies])\n",
    "        if args.normalize_input:\n",
    "            x_data = x_data/256.0\n",
    "        if args.use_cropping:\n",
    "            r = np.random.randint(10)\n",
    "            r2 = np.random.randint(10)\n",
    "            x_data = x_data[:,r:-10+r,r2:-10+r2]\n",
    "        if args.flip_input:\n",
    "            if np.random.randint(2) == 1:\n",
    "                x_data = x_data[:,::-1]\n",
    "            if np.random.randint(2) == 1:\n",
    "                x_data = x_data[:,:,::-1]\n",
    "        \n",
    "        yield x_data, np.array([[1,0],[0,1]])[y[indizies][:,0,0,0]]\n",
    "      "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(63, 86, 86, 3)\n(63, 2)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "tmp = next(next_data_pcam(x_train, y_train))\n",
    "print(tmp[0].shape)\n",
    "print(tmp[1].shape)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% dch\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "train the model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "if not os.path.exists('tensorboards'):\n",
    "    os.mkdir('tensorboards')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "10/10 - 16s - loss: 6.8758 - accuracy: 0.5222 - auc_1: 0.5299 - val_loss: 7.8032 - val_accuracy: 0.5159 - val_auc_1: 0.5159\n",
      "Epoch 2/3\n",
      "10/10 - 10s - loss: 7.8800 - accuracy: 0.5111 - auc_1: 0.5111 - val_loss: 6.9078 - val_accuracy: 0.5714 - val_auc_1: 0.5714\n",
      "Epoch 3/3\n",
      "10/10 - 9s - loss: 7.4450 - accuracy: 0.5381 - auc_1: 0.5381 - val_loss: 8.1870 - val_accuracy: 0.4921 - val_auc_1: 0.4921\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard('tensorboards/tb')\n",
    "history = model.fit_generator(next_data_pcam(x_train, y_train),\n",
    "                        validation_steps=10,\n",
    "                        steps_per_epoch=100,\n",
    "                        epochs=args.num_of_epochs,\n",
    "                        validation_data=next_data_pcam(x_valid, y_valid),\n",
    "                        workers=1, verbose=2,\n",
    "                        callbacks=[tensorboard])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "if not os.path.exists('tf_models'):\n",
    "    os.mkdir('tf_models')\n",
    "model.save_weights('./tf_models/tf_model.h5')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just some pseudo output\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 1.0, 0.0, 5.1617353767212855)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "size = 100000\n",
    "samples = np.random.beta(1,5,size=size)\n",
    "plt.hist(samples, bins=100, density=True)\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.axis((0.0,1.0,y1,y2))\n",
    "# axes.set_ylim([ymin,ymax])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% dch\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !pip install seaborn\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% dch\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# save all history data\n",
    "\n",
    "if not os.path.exists('outputs'):\n",
    "    os.mkdir('outputs')\n",
    "\n",
    "with open('outputs/all-history.json','w') as f:\n",
    "    json.dump(str(history.history),f)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'loss': 6.875818032026291, 'accuracy': 0.53809524, 'auc_1': 0.53809524, 'val_loss': 6.907755374908447, 'val_accuracy': 0.5714286, 'val_auc_1': 0.57142854}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "params = {}\n",
    "for p in history.history:\n",
    "    if p.find('loss') >= 0:\n",
    "        params[p] = np.min(history.history[p])\n",
    "    else:\n",
    "        params[p] = np.max(history.history[p])\n",
    "        \n",
    "with open('outputs/history-summary.json','w') as f:\n",
    "    json.dump(str(params),f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "dvc-cc",
   "language": "python",
   "display_name": "dvc-cc"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}